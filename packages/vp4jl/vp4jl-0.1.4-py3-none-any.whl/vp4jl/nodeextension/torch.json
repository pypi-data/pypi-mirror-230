{
  "description": "The torch tensor type definition",
  "enable": true,
  "nodes": {
    
    "Torch Tensor Ones": {
   "type": "Torch Tensor Ones",
      "category": "math",
      "title": "tensor ones",
      "externalImports": "import torch",
      "sourceCode": "{{indent}}{{{outputs.0}}}=torch.tensor({{{inputs.0}}})",
      "tooltip": "Returns a tensor filled with the scalar value 1, with the shape defined by the variable argument size.",
      "inputs": {
         "input": {
          "title": "Value",
          "dataType": "list"
        }
      },
      "outputs":{
        "output": {
          "title": "output",
          "dataType": "torch.tensor"
        }
      }
    },
    "Stack": {
      "type": "Stack",
      "category": "function",
      "title": "Stack",
      "tooltip": "Concatenates a sequence of tensors along a new dimension.",
      "externalImports": "import torch",
      "sourceCode": "{{indent}}{{{outputs.1}}} = torch.stack({{{inputs.1}}})\n{{{outputs.0}}}",
      "inputs": {
        "execIn": {
          "title": "execIn",
          "dataType": "exec",
          "showWidget": false,
          "showTitle": false
        },
        "input1": {
          "title": "list or tensor",
          "dataType": "list",
          "defaultValue": "[]"
        },
        "input2": {
          "title": "dim",
          "dataType": "integer",
          "defaultValue": "0"
        }
      },
      "outputs": {
        "execOut": {
          "title": "execOut",
          "dataType": "exec",
          "showWidget": false,
          "showTitle": false
        },
        "stackedtensor": {
          "title": "stacked tensor",
          "dataType": "torch.tensor",
          "defaultValue": "[]"
        }
      }
    },
    "Slice": {
      "type": "Slice",
      "category": "math",
      "title": "Get",
      "tooltip": "Tensor slicing",
      "sourceCode": "{{indent}}{{{outputs.0}}} = {{{inputs.0}}}{{{inputs.1}}}",
      "inputs": {
        "input": {
          "title": "input",
          "dataType": "torch.tensor"
        },
        "slice": {
          "title": "slice",
          "dataType": "list",
          "defaultValue": "[:]"
        }
      },
      "outputs": {
        "output": {
          "title": "output",
          "dataType": "torch.tensor",
          "defaultValue": "[]"
        }
      }
    },
    "tensor / float": {
      "type": "tensor / float",
      "category": "math",
      "title": "/",
      "tooltip": "Tensor Divide by a scalar",
      "sourceCode": "{{indent}}{{{outputs.0}}} = {{{inputs.0}}}/{{{inputs.1}}}",
      "inputs": {
        "tensor": {
          "title": "tensor",
          "dataType": "torch.tensor"
        },
        "float": {
          "title": "float",
          "dataType": "float",
          "defaultValue": "1.0"
        }
      },
      "outputs": {
        "output": {
          "title": "tensor",
          "dataType": "torch.tensor"
        }
      }
    },
    "Float - Tensor": {
      "type": "Float - Tensor",
      "category": "math",
      "title": "-",
      "tooltip": "A scalar minus a Tensor",
      "sourceCode": "{{indent}}{{{outputs.0}}} = {{{inputs.0}}} - {{{inputs.1}}}",
      "inputs": {
        "float": {
          "title": "float",
          "dataType": "float",
          "defaultValue": "1.0"
        },
        "input": {
          "title": "tensor",
          "dataType": "torch.tensor"
        }
      },
      "outputs": {
        "output": {
          "title": "tensor",
          "dataType": "torch.tensor"
        }
      }
    },
    "Unsqueeze": {
      "type": "Unsqueeze",
      "category": "function",
      "title": "Unsqueeze",
      "tooltip": "Returns a new tensor with a dimension of size one inserted at the specified position.",
      "externalImports": "import torch",
      "sourceCode": "{{indent}}{{{outputs.1}}} = torch.unsqueeze({{{inputs.1}}}, {{{inputs.2}}})\n{{{outputs.0}}}",
      "inputs": {
        "execIn": {
          "title": "execIn",
          "dataType": "exec",
          "showWidget": false,
          "showTitle": false
        },
        "input": {
          "title": "input",
          "dataType": "torch.tensor"
        },
        "dim": {
          "title": "dim",
          "dataType": "integer",
          "defaultValue": "0"
        }
      },
      "outputs": {
        "execOut": {
          "title": "execOut",
          "dataType": "exec",
          "showWidget": false,
          "showTitle": false
        },
        "output": {
          "title": "output",
          "dataType": "torch.tensor"
        }
      }
    }
  },
  "types": {
    "tensor": {
      "default": "",
      "widget": "TextInput",
      "shownInColor": "hsl(10, 50%, 60%)"
    }
  },
  "imageTypeConversion": {
    "torch.tensor": {
      "torch.tensor": {
        "function_definition": "def tensor2tensor(src_image, dest_metadata_list):\n    import torch\n    image = src_image[\"value\"].clone()\n    if dest_metadata_list is None:\n        return {\n        \"dataType\": src_image[\"dataType\"],\n        \"value\": image,\n        \"metadata\": src_image['metadata'],\n    }\n    \n    def find_matched_color_channel(src_metadata, dest_metadata_list):\n        # Same as the previous function, as this logic is independent of the data format\n        for metadata in dest_metadata_list:\n            if metadata[\"colorChannel\"] == src_metadata[\"colorChannel\"]:\n                return metadata\n\n        if src_metadata[\"colorChannel\"] in [\"grb\", \"gbr\"]:\n            for metadata in dest_metadata_list:\n                if metadata[\"colorChannel\"] in [\"rgb\", \"gbr\"]:\n                    return metadata\n\n        return dest_metadata_list[0]\n\n    src_metadata = src_image[\"metadata\"]\n    dest_metadata = find_matched_color_channel(src_metadata, dest_metadata_list)\n\n    # Handle batched images\n    if src_metadata.get(\"isMiniBatched\", False):\n        batch_dim = 0\n    else:\n        batch_dim = None\n\n    # Convert color space\n    if (\n        src_metadata[\"colorChannel\"] == \"grayscale\"\n        and dest_metadata[\"colorChannel\"] == \"grayscale\"\n    ):\n        pass  # No need for conversion\n    elif (\n        src_metadata[\"colorChannel\"] == \"grayscale\"\n        and dest_metadata[\"colorChannel\"] != \"grayscale\"\n    ):\n        image = image.unsqueeze(-1).repeat(1, 1, 1, 3)\n    elif (\n        src_metadata[\"colorChannel\"] != \"grayscale\"\n        and dest_metadata[\"colorChannel\"] == \"grayscale\"\n    ):\n        if src_metadata[\"channelOrder\"] == \"channelFirst\":\n            if src_metadata[\"colorChannel\"] == \"rgb\":\n                weights = (\n                    torch.tensor([0.299, 0.587, 0.114])\n                    .unsqueeze(-1)\n                    .unsqueeze(-1)\n                    .to(image.device)\n                )\n            else:  # gbr\n                weights = (\n                    torch.tensor([0.587, 0.114, 0.299])\n                    .unsqueeze(-1)\n                    .unsqueeze(-1)\n                    .to(image.device)\n                )\n            if batch_dim is not None:\n                image = (image * weights).sum(dim=1)\n            else:\n                image = (image * weights).sum(dim=0)\n        else:\n            if src_metadata[\"colorChannel\"] == \"rgb\":\n                weights = torch.tensor([0.299, 0.587, 0.114]).to(image.device)\n            else:  # gbr\n                weights = torch.tensor([0.587, 0.114, 0.299]).to(image.device)\n            if batch_dim is not None:\n                image = (image * weights).sum(dim=3)\n            else:\n                image = (image * weights).sum(dim=2)\n\n    elif src_metadata[\"colorChannel\"] == \"gbr\" and dest_metadata[\"colorChannel\"] == \"rgb\":\n        if src_metadata[\"channelOrder\"] == \"channelLast\":\n            if batch_dim is not None:\n                image = image[..., [2, 0, 1]]\n            else:\n                image = image[:, :, [2, 0, 1]]\n        elif src_metadata[\"channelOrder\"] == \"channelFirst\":\n            if batch_dim is not None:\n                image = image[:, [2, 0, 1], :, :]\n            else:\n                image = image[[2, 0, 1], :, :]\n\n    elif src_metadata[\"colorChannel\"] == \"rgb\" and dest_metadata[\"colorChannel\"] == \"gbr\":\n        if src_metadata[\"channelOrder\"] == \"channelLast\":\n            if batch_dim is not None:\n                image = image[..., [1, 2, 0]]\n            else:\n                image = image[:, :, [1, 2, 0]]\n        elif src_metadata[\"channelOrder\"] == \"channelFirst\":\n            if batch_dim is not None:\n                image = image[:, [1, 2, 0], :, :]\n            else:\n                image = image[[1, 2, 0], :, :]\n\n    # Adjust intensity range\n    if (\n        src_metadata[\"intensityRange\"] == \"0-255\"\n        and dest_metadata[\"intensityRange\"] == \"0-1\"\n    ):\n        image = image.float() / 255.0\n    elif (\n        src_metadata[\"intensityRange\"] == \"0-1\"\n        and dest_metadata[\"intensityRange\"] == \"0-255\"\n    ):\n        image = image * 255\n\n    # Adjust channel order\n    if (\n        src_metadata[\"channelOrder\"] == \"channelFirst\"\n        and dest_metadata[\"channelOrder\"] == \"channelLast\"\n    ):\n        if batch_dim is not None:\n            image = image.permute(batch_dim, 2, 3, 1)\n        else:\n            image = image.permute(1, 2, 0)\n    elif (\n        src_metadata[\"channelOrder\"] == \"channelLast\"\n        and dest_metadata[\"channelOrder\"] == \"channelFirst\"\n    ):\n        if batch_dim is not None:\n            image = image.permute(batch_dim, 3, 1, 2)\n        else:\n            image = image.permute(2, 0, 1)\n\n    # Handle batched destination image\n    if dest_metadata.get(\"isMiniBatched\", False) and not src_metadata.get(\n        \"isMiniBatched\", False\n    ):\n        image = image.unsqueeze(0)\n    elif not dest_metadata.get(\"isMiniBatched\", False) and src_metadata.get(\n        \"isMiniBatched\", False\n    ):\n        image = image.squeeze(0)\n\n    if dest_metadata[\"channelOrder\"] == \"none\":\n        if src_metadata[\"channelOrder\"] == \"channelFirst\":\n            image = image.squeeze(0)\n\n    # Create destination image with new metadata and converted values\n    dest_image = {\n        \"dataType\": src_image[\"dataType\"],\n        \"value\": image,\n        \"metadata\": dest_metadata,\n    }\n\n    return dest_image",
        "function_name": "tensor2tensor"
      },
      "numpy.ndarray": {
        "function_definition": "def tensor2ndarray(src_image):\n  import copy\n  numpy_image = copy.deepcopy(src_image['value'].cpu().numpy())\n  return {\n       'dataType': 'numpy.ndarray',\n       'value': numpy_image,\n       'metadata': src_image['metadata']\n  }",
        "function_name": "tensor2ndarray"
      }
    }
  }
}
