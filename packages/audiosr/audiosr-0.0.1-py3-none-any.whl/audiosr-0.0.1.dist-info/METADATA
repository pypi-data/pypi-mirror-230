Metadata-Version: 2.1
Name: audiosr
Version: 0.0.1
Summary: This package is written for text-to-audio/music generation.
Home-page: https://github.com/haoheliu/audiosr
Author: Haohe Liu
Author-email: haoheliu@gmail.com
License: MIT
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Programming Language :: Python :: Implementation :: PyPy
Requires-Python: >=3.7.0
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch >=1.13.0
Requires-Dist: torchaudio >=0.13.0
Requires-Dist: torchvision >=0.14.0
Requires-Dist: tqdm
Requires-Dist: gradio
Requires-Dist: pyyaml
Requires-Dist: einops
Requires-Dist: chardet
Requires-Dist: numpy <=1.23.5
Requires-Dist: soundfile
Requires-Dist: librosa ==0.9.2
Requires-Dist: scipy
Requires-Dist: pandas
Requires-Dist: unidecode
Requires-Dist: phonemizer
Requires-Dist: torchlibrosa >=0.0.9
Requires-Dist: transformers ==4.30.2
Requires-Dist: huggingface-hub
Requires-Dist: progressbar
Requires-Dist: ftfy
Requires-Dist: timm


# AudioSR: Versatile Audio Super-resolution at Scale

Pass your audio in, AudioSR will make it high fidelity! 

Work on all types of audio (e.g., music, speech, dog, raining, ...) & all sampling rates.

![Image Description](visualization.png)

## TODO
- [ ] Add gradio demo.
- [ ] Optimize the inference speed.

## Commandline Usage

## Installation
```shell
# Optional
conda create -n audiosr python=3.9; conda activate audiosr
# Install AudioLDM
pip3 install git+https://github.com/haoheliu/versatile_audio_super_resolution
```

## Usage

Process a list of files. The result will be saved at ./output by default.

```shell
audiosr -il batch.lst
```

Process a single audio file.
```shell
audiosr -i example/music.wav
```

Full usage instruction

```shell
> audiosr -h

> usage: audiosr [-h] -i INPUT_AUDIO_FILE [-il INPUT_FILE_LIST] [-s SAVE_PATH] [--model_name {basic,speech}] [-d DEVICE] [--ddim_steps DDIM_STEPS] [-gs GUIDANCE_SCALE] [--seed SEED]

optional arguments:
  -h, --help            show this help message and exit
  -i INPUT_AUDIO_FILE, --input_audio_file INPUT_AUDIO_FILE
                        Input audio file for audio super resolution
  -il INPUT_FILE_LIST, --input_file_list INPUT_FILE_LIST
                        A file that contains all audio files that need to perform audio super resolution
  -s SAVE_PATH, --save_path SAVE_PATH
                        The path to save model output
  --model_name {basic,speech}
                        The checkpoint you gonna use
  -d DEVICE, --device DEVICE
                        The device for computation. If not specified, the script will automatically choose the device based on your environment.
  --ddim_steps DDIM_STEPS
                        The sampling step for DDIM
  -gs GUIDANCE_SCALE, --guidance_scale GUIDANCE_SCALE
                        Guidance scale (Large => better quality and relavancy to text; Small => better diversity)
  --seed SEED           Change this value (any integer number) will lead to a different generation result.
```

## Cite our work

If you find this repo useful, please consider citing our work 
