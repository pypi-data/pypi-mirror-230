baseline:
  api-key: cc362e03e225e86476ac8d0a18460b40L05
  best-params:
    batch-size: 8
    epochs: 1
    head-size: 30
    learning-rate: 1e-4
  model-name: microsoft/deberta-base
  model-path: /bigwork/nhwpajjy/pre-trained-models/microsoft/deberta-base
  model-path-fine-tuned: /bigwork/nhwpajjy/pre-trained-models/deberta-base-fine-tuned
  params:
    batch-size:
    - 16
    epochs:
    - 15
    head-size:
    - 30
    learning-rate:
    - 1e-5
dataset:
  path-ibmsc-root: data/claim_stance_dataset_v1.csv
experiment:
  ibmsc:
    path-few-shots: experiment/ibmsc-few-shots.csv
    path-logs: ibm-sc-validation-time.logs
    path-results: ibm-sc-validation-run-time.tsv
    path-test: experiment/ibmsc-test.csv
    path-training: experiment/ibmsc-train.csv
    path-validation: experiment/ibmsc-validation.csv
  vast:
    path-few-shots: experiment/vast-few-shots.csv
    path-logs: vast-validation-time.logs
    path-results: vast-validation-run-time.tsv
    path-test: experiment/vast-test.csv
    path-training: experiment/vast-train.csv
    path-validation: experiment/vast-validation.csv
openai:
  key: ''
pre-trained-models:
  alpaca:
    model-name: wxjiao/alpaca-7b
    model-path: /bigwork/nhwpajjy/pre-trained-models/wxjiao/alpaca-7b
  gpt-j:
    model-name: EleutherAI/gpt-j-6B
    model-path: /bigwork/nhwpajjy/pre-trained-models/gptj-16
    learning-rate:
      - 2e-5
      - 5e-5
      - 1e-3
      - 1e-5
      - 1e-6
  models:
  - t5-base
  - bert-base-uncased
  - gpt2
  - opt
  - gpt2-xl
  path: /bigwork/nhwpajjy/pre-trained-models
prompt:
  batch-size: 16
  few-shot-size: 16
  logs: logs/prompt.log
#  model-input-limit: 2000
#  model-name: /bigwork/nhwpajjy/pre-trained-models/opt-66b
#  model-path: /bigwork/nhwpajjy/pre-trained-models/facebook/opt-30b
#  model-type: facebook/opt-30b
  model-input-limit: 1000
  model-name: gpt2
  model-path: gpt2
  model-type: gpt2
prompt-fine-tuning:
  best-params:
    batch-size: 16
    epochs: 1
    learning-rate: 2e-5
  few-shot-size: 4
  model-name: wxjiao/alpaca-7b
  model-path: /bigwork/nhwpajjy/pre-trained-models/gptj
  model-path-fine-tuned: /bigwork/nhwpajjy/pre-trained-models/gpt2-fine-tuned
  model-type: wxjiao/alpaca-7b
  params:
    batch-size:
    - 2
    epochs:
    - 20
    learning-rate:
    - 3e-4
    - 2e-5
topic-similarity:
  bow:
    ibmsc-test: null
    ibmsc-validation: 10
    vast-test: null
    vast-validation: null
  model-path:
    ibmsc-test: /bigwork/nhwpajjy/pre-trained-models/topic-models/ibmsc-test
    ibmsc-validation: /bigwork/nhwpajjy/pre-trained-models/topic-models/ibmsc-validation
    vast-test: /bigwork/nhwpajjy/pre-trained-models/topic-models/vast-test
    vast-validation: /bigwork/nhwpajjy/pre-trained-models/topic-models/vast-validation
  params:
    contextual_size: 768
    n_components: 15
    num_epochs: 100
  similarity-path:
    ibmsc-test: null
    ibmsc-validation: /bigwork/nhwpajjy/pre-trained-models/topic-models/similarities-ibmsc-validation.bin
    vast-test: null
    vast-validation: null
